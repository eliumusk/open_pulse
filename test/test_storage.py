"""
æµ‹è¯• Workflow å­˜å‚¨çš„ç®€åŒ–è„šæœ¬
ç”¨äºéªŒè¯ workflow æ•°æ®æ˜¯å¦æ­£ç¡®ä¿å­˜åˆ°æ•°æ®åº“
"""
import asyncio
import sqlite3
import json
from datetime import datetime
from agno.db.sqlite import SqliteDb
from agno.workflow import Workflow, Step
from agno.workflow.types import StepInput, StepOutput
from config.settings import DATABASE_FILE


def simple_newsletter_step(step_input: StepInput) -> StepOutput:
    """
    ç®€åŒ–çš„ newsletter ç”Ÿæˆæ­¥éª¤
    åªè¿”å›ä¸€ä¸ªç®€å•çš„æµ‹è¯•å†…å®¹ï¼Œä¸è°ƒç”¨ LLM
    """
    user_input = step_input.input or "AI and technology"
    
    newsletter_content = f"""
# ğŸ“° Test Newsletter

**Generated at:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**Topic:** {user_input}

## Summary

This is a simplified test newsletter to verify storage functionality.

## Key Points

1. **Storage Test**: Verifying that workflow outputs are saved correctly
2. **Database**: Using SQLite with Agno's default schema
3. **Table**: Data should be in the 'sessions' table
4. **Field**: Complete content should be in the 'runs' JSON field

## Conclusion

If you can see this complete content in the database, storage is working correctly!

---
**Newsletter ID:** test_{datetime.now().strftime('%Y%m%d_%H%M%S')}
**Length:** {len(user_input)} characters input
    """.strip()
    
    print(f"âœ… Generated test newsletter: {len(newsletter_content)} characters")
    
    return StepOutput(
        content=newsletter_content,
        success=True,
    )


def create_test_workflow(db: SqliteDb) -> Workflow:
    """
    åˆ›å»ºä¸€ä¸ªç®€åŒ–çš„æµ‹è¯• workflow
    åªæœ‰ä¸€ä¸ªæ­¥éª¤ï¼Œä¸éœ€è¦ LLM API
    """
    # å®šä¹‰æ­¥éª¤
    test_step = Step(
        name="Generate Test Newsletter",
        executor=simple_newsletter_step,
        description="Generate a simple test newsletter without LLM",
    )
    
    # åˆ›å»º workflow
    workflow = Workflow(
        name="Test Storage Workflow",
        description="Simplified workflow to test storage functionality",
        db=db,
        store_events=True,  # å­˜å‚¨æ‰€æœ‰äº‹ä»¶
        steps=[test_step],
    )
    
    return workflow


def check_database_storage():
    """
    æ£€æŸ¥æ•°æ®åº“ä¸­çš„ workflow æ•°æ®
    """
    print("\n" + "="*80)
    print("ğŸ“Š Database Storage Check")
    print("="*80 + "\n")
    
    try:
        conn = sqlite3.connect(DATABASE_FILE)
        cursor = conn.cursor()
        
        # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
        cursor.execute("""
            SELECT name FROM sqlite_master 
            WHERE type='table' 
            ORDER BY name
        """)
        tables = [row[0] for row in cursor.fetchall()]
        print(f"ğŸ“‹ Available tables: {', '.join(tables)}\n")
        
        # æ£€æŸ¥ agno_sessions è¡¨ä¸­çš„ workflow æ•°æ®ï¼ˆAgno é»˜è®¤è¡¨ï¼‰
        cursor.execute("""
            SELECT COUNT(*)
            FROM agno_sessions
            WHERE workflow_id IS NOT NULL
        """)
        workflow_count = cursor.fetchone()[0]
        print(f"ğŸ”¢ Workflow sessions in 'agno_sessions' table: {workflow_count}")

        # å¦‚æœæœ‰æ•°æ®ï¼Œæ˜¾ç¤ºæœ€æ–°çš„ä¸€æ¡
        if workflow_count > 0:
            cursor.execute("""
                SELECT session_id, workflow_id, runs, created_at
                FROM agno_sessions
                WHERE workflow_id IS NOT NULL
                ORDER BY created_at DESC
                LIMIT 1
            """)

            row = cursor.fetchone()
            if row:
                session_id, workflow_id, runs_json, created_at = row
                print(f"\nğŸ“ Latest workflow session:")
                print(f"  Session ID: {session_id}")
                print(f"  Workflow ID: {workflow_id}")
                print(f"  Created at: {datetime.fromtimestamp(created_at).strftime('%Y-%m-%d %H:%M:%S')}")

                # è§£æ runsï¼ˆå¯èƒ½éœ€è¦åŒé‡è§£æï¼‰
                if runs_json:
                    # ç¬¬ä¸€æ¬¡è§£æ
                    parsed = json.loads(runs_json)

                    # å¦‚æœç»“æœæ˜¯å­—ç¬¦ä¸²ï¼Œéœ€è¦å†è§£æä¸€æ¬¡ï¼ˆåŒé‡ JSON ç¼–ç ï¼‰
                    if isinstance(parsed, str):
                        runs = json.loads(parsed)
                    else:
                        runs = parsed

                    print(f"  Number of runs: {len(runs)}")

                    if runs and len(runs) > 0:
                        latest_run = runs[-1]
                        # runs å¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–å­—å…¸
                        if isinstance(latest_run, dict):
                            content = latest_run.get('content', '')
                        elif isinstance(latest_run, str):
                            content = latest_run
                        else:
                            content = str(latest_run)

                        print(f"\n  ğŸ“„ Content preview:")
                        print(f"  {content[:200]}...")
                        print(f"\n  âœ… Full content length: {len(content)} characters")

        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰å…¶ä»–å†—ä½™è¡¨
        redundant_tables = ['sessions', 'workflow_sessions', 'newsletter_sessions',
                           'digest_sessions', 'research_sessions']
        found_redundant = False
        for table_name in redundant_tables:
            if table_name in tables:
                cursor.execute(f"SELECT COUNT(*) FROM {table_name} WHERE workflow_id IS NOT NULL")
                count = cursor.fetchone()[0]
                if count > 0:
                    print(f"\nâš ï¸  Found {count} workflow sessions in '{table_name}' table (should be migrated!)")
                    found_redundant = True

        if not found_redundant:
            print(f"\nâœ… No redundant tables found - database is clean!")
        
        conn.close()
        
    except Exception as e:
        print(f"âŒ Error checking database: {e}")


async def run_test():
    """
    è¿è¡Œå®Œæ•´çš„æµ‹è¯•æµç¨‹
    """
    print("\n" + "="*80)
    print("ğŸ§ª Workflow Storage Test")
    print("="*80 + "\n")
    
    # 1. åˆ›å»ºæ•°æ®åº“å®ä¾‹
    print("1ï¸âƒ£  Creating database instance...")
    db = SqliteDb(db_file=DATABASE_FILE)
    print(f"   âœ… Database: {DATABASE_FILE}\n")
    
    # 2. åˆ›å»ºæµ‹è¯• workflow
    print("2ï¸âƒ£  Creating test workflow...")
    workflow = create_test_workflow(db)
    print(f"   âœ… Workflow: {workflow.name}\n")
    
    # 3. è¿è¡Œ workflow
    print("3ï¸âƒ£  Running workflow...")
    result = await workflow.arun(
        input="AI, quantum computing, and space exploration",
        user_id="test_user",
    )
    print(f"   âœ… Workflow completed")
    print(f"   ğŸ“Š Status: {result.status if hasattr(result, 'status') else 'completed'}")
    print(f"   ğŸ“ Content length: {len(result.content)} characters\n")
    
    # 4. æ˜¾ç¤ºç»“æœé¢„è§ˆ
    print("4ï¸âƒ£  Result preview:")
    print("   " + "-"*76)
    preview = result.content[:300].replace('\n', '\n   ')
    print(f"   {preview}...")
    print("   " + "-"*76 + "\n")
    
    # 5. æ£€æŸ¥æ•°æ®åº“å­˜å‚¨
    print("5ï¸âƒ£  Checking database storage...")
    await asyncio.sleep(1)  # ç­‰å¾…æ•°æ®å†™å…¥
    check_database_storage()
    
    print("\n" + "="*80)
    print("âœ… Test completed!")
    print("="*80 + "\n")


if __name__ == "__main__":
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                              â•‘
â•‘              ğŸ§ª Workflow Storage Test ğŸ§ª                     â•‘
â•‘                                                              â•‘
â•‘  This script tests if workflow outputs are correctly         â•‘
â•‘  saved to the database.                                      â•‘
â•‘                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    asyncio.run(run_test())

